{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_label_dict = {\"n\" : 0, \"y\" : 1}\n",
    "def encode_label(x):\n",
    "    return encoded_label_dict.get(x,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../data/REVISION DATASET_b.xlsx\"\n",
    "df = pd.read_excel(fp,sheet_name=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>expresses a pain point</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_epochs</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>Type of Pain</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Second category</th>\n",
       "      <th>Third category</th>\n",
       "      <th>Fourth category</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emmanuel Olabode</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@ifemeetstech your pr team can help bridge the...</td>\n",
       "      <td>y</td>\n",
       "      <td>42176</td>\n",
       "      <td>1434841837</td>\n",
       "      <td>612397168788406016</td>\n",
       "      <td>/olabodeEO/status/612397168788406272</td>\n",
       "      <td>1955234486</td>\n",
       "      <td>olabodeEO</td>\n",
       "      <td>gap</td>\n",
       "      <td>Operational issues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alviniecððâ¨</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mcdonalds really bein missing uhp people food ...</td>\n",
       "      <td>y</td>\n",
       "      <td>2014-09-01 23:25:17</td>\n",
       "      <td>1409613917</td>\n",
       "      <td>506583600599662592</td>\n",
       "      <td>/ohhamazing/status/506583600599662592</td>\n",
       "      <td>2723652417</td>\n",
       "      <td>ohhamazing</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>Product feature or quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bobby</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>if they thought that little of him, why was he...</td>\n",
       "      <td>y</td>\n",
       "      <td>43720</td>\n",
       "      <td>1568242832</td>\n",
       "      <td>1171921495309910016</td>\n",
       "      <td>/Bobbythegreat/status/1171921495309914112</td>\n",
       "      <td>33740752</td>\n",
       "      <td>Bobbythegreat</td>\n",
       "      <td>gap</td>\n",
       "      <td>Product feature or quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elgen Bodenstien</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>when towns have locally owned  business capita...</td>\n",
       "      <td>y</td>\n",
       "      <td>2019-09-05 23:34:22</td>\n",
       "      <td>1567726462</td>\n",
       "      <td>1169755684122086912</td>\n",
       "      <td>/bodenstien/status/1169755684122087424</td>\n",
       "      <td>1167585352464424960</td>\n",
       "      <td>bodenstien</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Company's image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robyn</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@arma_vancouver health information in records ...</td>\n",
       "      <td>y</td>\n",
       "      <td>2019-01-23 22:43:08</td>\n",
       "      <td>1548283388</td>\n",
       "      <td>1088205518886190976</td>\n",
       "      <td>/RobynCBird/status/1088205518886191104</td>\n",
       "      <td>2206030555</td>\n",
       "      <td>RobynCBird</td>\n",
       "      <td>fitbit</td>\n",
       "      <td>Company's image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fullname  is_retweet  likes  replies  retweets  \\\n",
       "0     Emmanuel Olabode           0      1        1         1   \n",
       "1  Alviniecððâ¨           0      0        0         0   \n",
       "2                Bobby           0      0        0         0   \n",
       "3     Elgen Bodenstien           0      0        0         0   \n",
       "4                Robyn           0      3        1         1   \n",
       "\n",
       "                                                text expresses a pain point  \\\n",
       "0  @ifemeetstech your pr team can help bridge the...                      y   \n",
       "1  mcdonalds really bein missing uhp people food ...                      y   \n",
       "2  if they thought that little of him, why was he...                      y   \n",
       "3  when towns have locally owned  business capita...                      y   \n",
       "4  @arma_vancouver health information in records ...                      y   \n",
       "\n",
       "             timestamp  timestamp_epochs             tweet_id  \\\n",
       "0                42176        1434841837   612397168788406016   \n",
       "1  2014-09-01 23:25:17        1409613917   506583600599662592   \n",
       "2                43720        1568242832  1171921495309910016   \n",
       "3  2019-09-05 23:34:22        1567726462  1169755684122086912   \n",
       "4  2019-01-23 22:43:08        1548283388  1088205518886190976   \n",
       "\n",
       "                                   tweet_url              user_id  \\\n",
       "0       /olabodeEO/status/612397168788406272           1955234486   \n",
       "1      /ohhamazing/status/506583600599662592           2723652417   \n",
       "2  /Bobbythegreat/status/1171921495309914112             33740752   \n",
       "3     /bodenstien/status/1169755684122087424  1167585352464424960   \n",
       "4     /RobynCBird/status/1088205518886191104           2206030555   \n",
       "\n",
       "        username      BRAND                Type of Pain Subjectivity  \\\n",
       "0      olabodeEO        gap          Operational issues          NaN   \n",
       "1     ohhamazing  mcdonalds  Product feature or quality          NaN   \n",
       "2  Bobbythegreat        gap  Product feature or quality          NaN   \n",
       "3     bodenstien    walmart             Company's image          NaN   \n",
       "4     RobynCBird     fitbit             Company's image          NaN   \n",
       "\n",
       "  Second category Third category Fourth category   Dataset  \n",
       "0             NaN            NaN             NaN  Original  \n",
       "1             NaN            NaN             NaN  Original  \n",
       "2             NaN            NaN             NaN  Original  \n",
       "3             NaN            NaN             NaN  Original  \n",
       "4             NaN            NaN             NaN  Original  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"text\",\"expresses a pain point\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"expresses a pain point\"].apply(lambda x: encode_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(txt):\n",
    "    return p.clean(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>expresses a pain point</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ifemeetstech your pr team can help bridge the...</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>your pr team can help bridge the communication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mcdonalds really bein missing uhp people food ...</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>mcdonalds really bein missing uhp people food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if they thought that little of him, why was he...</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>if they thought that little of him, why was he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when towns have locally owned  business capita...</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>when towns have locally owned business capital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@arma_vancouver health information in records ...</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>health information in records means vulnerabil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text expresses a pain point  \\\n",
       "0  @ifemeetstech your pr team can help bridge the...                      y   \n",
       "1  mcdonalds really bein missing uhp people food ...                      y   \n",
       "2  if they thought that little of him, why was he...                      y   \n",
       "3  when towns have locally owned  business capita...                      y   \n",
       "4  @arma_vancouver health information in records ...                      y   \n",
       "\n",
       "   target                                         clean_text  \n",
       "0       1  your pr team can help bridge the communication...  \n",
       "1       1  mcdonalds really bein missing uhp people food ...  \n",
       "2       1  if they thought that little of him, why was he...  \n",
       "3       1  when towns have locally owned business capital...  \n",
       "4       1  health information in records means vulnerabil...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3348\n",
       "1    1252\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in df.clean_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "MAX_LEN = 35\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.clean_text[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, stratify=None, random_state=2021)\n",
    "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, stratify=None, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (4600, 4)\n",
      "TRAIN Dataset: (3680, 4)\n",
      "VALID Dataset: (460, 4)\n",
      "TEST Dataset: (460, 4)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader\n",
    "train_dataset = train.reset_index(drop=True)\n",
    "valid_dataset = valid.reset_index(drop=True)\n",
    "test_dataset = test.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "validating_set = Triage(valid_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validating_loader = DataLoader(validating_set, **valid_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcuate the accuracy of the model\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    n_wrong = 0\n",
    "    total = 0\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    state = torch.get_rng_state()\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, attention_mask=mask, labels=targets)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            tr_loss += loss\n",
    "            big_val, big_idx = torch.max(logits, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    torch.set_rng_state(state)\n",
    "    return epoch_loss, epoch_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the roberta model\n",
    "def train(epoch, training_loader, testing_loader, lr_sched):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids, attention_mask=mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        tr_loss += loss\n",
    "        big_val, big_idx = torch.max(logits, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _!=0 and _%100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 100 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 100 steps: {accu_step}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sched.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    valid_loss, valid_accu = validate(model,testing_loader)\n",
    "    return model, epoch_loss, epoch_accu, valid_loss, valid_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2021)\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "# Creating the optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(training_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "running_val_loss = float('inf')\n",
    "running_trn_loss = float('inf')\n",
    "trn_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    m, trn_loss, trn_acc, val_loss, val_acc = train(epoch, training_loader, validating_loader, lr_scheduler)\n",
    "    trn_losses.append(trn_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    if (val_loss < running_val_loss) and (val_loss < trn_loss):\n",
    "        running_val_loss = val_loss\n",
    "        running_trn_loss = trn_loss\n",
    "        # Save the best model\n",
    "        output_model_file = f'../models/best-ft-roberta-painpoint-maxlen35-bs16-lr-sched.pt'\n",
    "        model_to_save = m\n",
    "        torch.save(model_to_save, output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Epoch vs Loss Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../models/best-ft-roberta-painpoint-maxlen35-bs16-lr-sched.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query, model, tokenizer, device=\"cuda\"):\n",
    "    tokens = tokenizer.encode(query)\n",
    "    all_tokens = len(tokens)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]\n",
    "    used_tokens = len(tokens)\n",
    "    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "    mask = torch.ones_like(tokens)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "    return real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08806031942367554"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"This is bad.\n",
    "\"\"\"\n",
    "predict(query,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, preds_probas = [],[]\n",
    "for i, row in test_dataset.iterrows():\n",
    "    query = row[\"clean_text\"]\n",
    "    pred = predict(query,model,tokenizer)\n",
    "    preds_probas.append(pred)\n",
    "    if pred >= 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[315,  17],\n",
       "       [ 54,  74]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = test_dataset.target.values\n",
    "y_pred = preds\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "acc = accuracy_score(y_true,y_pred)\n",
    "precision = precision_score(y_true,y_pred)\n",
    "recall = recall_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.56521739130434; Precision:81.31868131868131; Recall:57.8125\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.85      0.95      0.90       332\n",
      "           y       0.81      0.58      0.68       128\n",
      "\n",
      "    accuracy                           0.85       460\n",
      "   macro avg       0.83      0.76      0.79       460\n",
      "weighted avg       0.84      0.85      0.84       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=[\"n\",\"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
